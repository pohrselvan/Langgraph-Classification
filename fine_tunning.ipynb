{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85700f62",
   "metadata": {},
   "source": [
    "# Fine tunning Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "500312d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.8.0\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afd250e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: packaging in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: pandas in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (2025.3.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (2.2.6)\n",
      "Requirement already satisfied: xxhash in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (0.32.3)\n",
      "Requirement already satisfied: dill in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: filelock in /home/selvan/rag/rag/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/selvan/rag/rag/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/selvan/rag/rag/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.6)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/selvan/rag/rag/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/selvan/rag/rag/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/selvan/rag/rag/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/selvan/rag/rag/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/selvan/rag/rag/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/selvan/rag/rag/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/selvan/rag/rag/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/selvan/rag/rag/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/selvan/rag/rag/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/selvan/rag/rag/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/selvan/rag/rag/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/selvan/rag/rag/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/selvan/rag/rag/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/selvan/rag/rag/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace2efd",
   "metadata": {},
   "source": [
    "## 1.Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f8b95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selvan/rag/rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"fancyzhx/amazon_polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030da112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'title', 'content'],\n",
       "        num_rows: 3600000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'title', 'content'],\n",
       "        num_rows: 400000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31bf3f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'title': 'Stuning even for the non-gamer',\n",
       " 'content': 'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 1-> positive and 0-> negative\n",
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5faf49bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d896448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[\"train\"].shuffle(seed=42).select(range(20000))\n",
    "test_data = data[\"test\"].shuffle(seed=42).select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b328613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['label', 'title', 'content'],\n",
       "     num_rows: 20000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['label', 'title', 'content'],\n",
       "     num_rows: 2000\n",
       " }))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8ba6e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "labels = data[\"train\"][\"label\"]\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0b86c",
   "metadata": {},
   "source": [
    "## 2.Loading the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ddbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c198db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n",
      "==============================\n",
      "tokens:{'input_ids': [101, 2023, 2614, 2650, 2001, 3376, 999, 2009, 23262, 1996, 12411, 7301, 1999, 2115, 2568, 2061, 2092, 1045, 2052, 28667, 8462, 4859, 2009, 2130, 2000, 2111, 2040, 5223, 6819, 2094, 1012, 2208, 2189, 999, 1045, 2031, 2209, 1996, 2208, 10381, 4948, 2080, 2892, 2021, 2041, 1997, 2035, 1997, 1996, 2399, 1045, 2031, 2412, 2209, 2009, 2038, 1996, 2190, 2189, 999, 2009, 10457, 2185, 2013, 13587, 9019, 2075, 1998, 3138, 1037, 4840, 2121, 3357, 2007, 24665, 3686, 7334, 1998, 3969, 3993, 19505, 1012, 2009, 2052, 17894, 3087, 2040, 14977, 2000, 4952, 999, 1034, 1035, 1034, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "text = data[\"train\"][0][\"content\"]\n",
    "tokens = tokenizer(text,padding=\"max_length\",truncation=True,max_length=216)\n",
    "print(f\"Text:{text}\")\n",
    "print(\"=\"*30)\n",
    "print(f\"tokens:{tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef274e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:03<00:00, 5012.92 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 5240.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the data \n",
    "def tokenizer_function(examples):\n",
    "  return tokenizer(examples[\"content\"],padding=\"max_length\",truncation=True,max_length=256)\n",
    "\n",
    "tokenized_train_data = train_data.map(tokenizer_function,batched=True)\n",
    "tokenized_test_data = test_data.map(tokenizer_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffff0db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'title', 'content', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057f23a",
   "metadata": {},
   "source": [
    "## 3.Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.53.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238ec1c",
   "metadata": {},
   "source": [
    "## 3.Freezing the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f37448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1538\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers except the classifier\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Keep only the classification head trainable\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ccad4",
   "metadata": {},
   "source": [
    "## 4.Defining the training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51accff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=epoch,\n",
      "eval_use_gather_object=False,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_revision=None,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "liger_kernel_config=None,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./results,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./results,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           \n",
    "    eval_strategy=\"epoch\",     \n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,             \n",
    "    weight_decay=0.01,               \n",
    "    save_total_limit=2,              \n",
    "    load_best_model_at_end=True,     \n",
    "    logging_dir=\"./logs\",            \n",
    "    logging_steps=100,               \n",
    "    fp16=True                        \n",
    ")\n",
    "\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc0eb8",
   "metadata": {},
   "source": [
    "## 5.Defing the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b8235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 4.20kB [00:00, 8.94MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "metric = load(\"accuracy\") \n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "979fffe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8}\n"
     ]
    }
   ],
   "source": [
    "predictions = [0, 1, 1, 0, 1]\n",
    "references =  [0, 1, 0, 0, 1]\n",
    "\n",
    "results = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # for dynamic paadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f30a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4402/259409160.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                        \n",
    "    args=training_args,                 \n",
    "    train_dataset=tokenized_train_data,\n",
    "    eval_dataset=tokenized_test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,        \n",
    "    compute_metrics=compute_metrics     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80ece03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 08:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.651500</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.618662</td>\n",
       "      <td>0.754500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.618100</td>\n",
       "      <td>0.610606</td>\n",
       "      <td>0.745500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.6449039916992187, metrics={'train_runtime': 497.4175, 'train_samples_per_second': 120.623, 'train_steps_per_second': 7.539, 'total_flos': 7893331660800000.0, 'train_loss': 0.6449039916992187, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c40dd8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 08:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.602400</td>\n",
       "      <td>0.586796</td>\n",
       "      <td>0.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.583900</td>\n",
       "      <td>0.567042</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.575600</td>\n",
       "      <td>0.562973</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.5919004740397136, metrics={'train_runtime': 501.8527, 'train_samples_per_second': 119.557, 'train_steps_per_second': 7.472, 'total_flos': 7893331660800000.0, 'train_loss': 0.5919004740397136, 'epoch': 3.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "176a66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 07:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.560600</td>\n",
       "      <td>0.548630</td>\n",
       "      <td>0.751500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>0.533319</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.549300</td>\n",
       "      <td>0.530634</td>\n",
       "      <td>0.788000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.557756825764974, metrics={'train_runtime': 478.7053, 'train_samples_per_second': 125.338, 'train_steps_per_second': 7.834, 'total_flos': 7893331660800000.0, 'train_loss': 0.557756825764974, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8936bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
